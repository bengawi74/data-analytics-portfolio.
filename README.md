# Classical Machine Learning Portfolio

This repository contains a collection of classical machine learning notebooks completed as part of my coursework. The goal is to build a strong foundation in data analysis, model training, evaluation, and feature understanding before moving into deep learning and full-stack AI systems.

## Projects Included

The portfolio covers several key machine learning topics:

• Exploratory Data Analysis (EDA)  
• Information Gain and Decision Trees  
• Classification Methods  
• Model Evaluation (accuracy, confusion matrix, precision, recall, F1)  
• Dimensionality Reduction (PCA and LDA)  
• Ensemble Methods (Random Forest, Boosting, Bagging)

Each notebook focuses on one topic, explains the ideas behind it, and includes practical examples.

## Notebook Descriptions

• EDA: Looks at the structure of the data, patterns, correlations, and visual summaries.  
• Information Gain: Shows how decision trees choose splits and why some features are more useful than others.  
• Classification: Trains different classifiers and compares how they perform.  
• Model Evaluation I and II: Reviews accuracy, confusion matrices, and other evaluation tools.  
• PCA and LDA: Reduces the number of features while keeping important information.  
• Ensemble Methods: Combines multiple models to improve stability and accuracy.

## What I Learned

These notebooks helped me build a solid base in classical machine learning. I learned how to explore data properly, compare different models, understand evaluation metrics, and reduce dimensionality. This work made it easier for me to move into deep learning and computer vision projects later on, because I understood the fundamentals behind model behavior and performance.

